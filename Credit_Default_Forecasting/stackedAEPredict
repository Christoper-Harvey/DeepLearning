function [pred] = stackedAEPredict(theta, inputSize, hiddenSize, numClasses, netconfig, data)

% We first extract the part which compute the softmax gradient
softmaxTheta = reshape(theta(1:hiddenSize*numClasses), numClasses, hiddenSize); %dimen: 10 x 200

% Extract out the "stack"
stack = params2stack(theta(hiddenSize*numClasses+1:end), netconfig);

m = columns(data);

z1 = (stack{1}.w * data) + repmat(stack{1}.b, 1, m);
a2 = sigmoid(z1); %dimen: 200 x 10,000
z2 = (stack{2}.w * a2) + repmat(stack{2}.b, 1, m);
a3 = sigmoid(z2); %dimen: 200 x 10,000

z3 = bsxfun(@plus, (stack{3}.w * a3), stack{3}.b);
a4 = sigmoid(z3);

M = softmaxTheta * a4;
M = bsxfun(@minus, M, max(M, [], 1)); %preventing overflow of sigmoid function
hyp = exp(M);
hyp = bsxfun(@rdivide, hyp, sum(hyp)); %normalizing values

%make prediction: for every example (column), return index with max value
[scrap, pred] = max(hyp, [], 1);

end

function sigm = sigmoid(x)
    sigm = 1 ./ (1 + exp(-x));
end
